{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efe610a-14a7-4210-a56e-1f2c21c83c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc3f6c10-25ed-40d5-beab-284426734cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from datetime import datetime, timedelta\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e17f825b-1ab5-431a-94d0-01205c28e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_config():\n",
    "    host = input(\"Enter the database host (default: localhost): \") or 'localhost'\n",
    "    user = input(\"Enter your database username (default: root): \") or 'root'\n",
    "    password = getpass.getpass(\"Enter your database password: \")\n",
    "    database = 'financial_data'\n",
    "\n",
    "    return {\n",
    "        'host': host,\n",
    "        'user': user,\n",
    "        'password': password,\n",
    "        'database': database\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "939513c9-d94f-4d0d-bb83-bee60268f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = {\n",
    "    'GOLD_FUTURES': 'GC=F',       # Gold Futures \n",
    "    'SP_INDEX': '^GSPC',     # S&P 500 Index\n",
    "    'DJ_INDEX': '^DJI',      # Dow Jones Index\n",
    "    'EG_CORP': 'EGO',        # Eldorado Gold Corporation\n",
    "    'EUR_USD': 'EURUSD=X',   # EUR/USD Exchange rate\n",
    "    'OIL_FUTURES': 'BZ=F',   # Brent Crude Oil Futures\n",
    "    'WTI_OIL': 'CL=F',       # Crude Oil WTI Futures\n",
    "    'SILVER_FUTURES': 'SI=F', # Silver Futures\n",
    "    'US_BOND_RATE': '^TNX',  # US Bond Rate\n",
    "    'PLATINUM_FUTURES': 'PL=F', # Platinum Futures\n",
    "    'PALLADIUM_FUTURES': 'PA=F', # Palladium Futures\n",
    "    'GOLD_MINERS': 'GDX',    # Gold Miners ETF\n",
    "    'OIL_ETF': 'USO',        # Oil ETF USO\n",
    "    'USD_INDEX': 'DX-Y.NYB'  # US Dollar Index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efe704f4-9f65-46c7-990b-7a7730159de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database(db_config):\n",
    "    \"\"\"Connect to the MySQL database.\"\"\"\n",
    "    return mysql.connector.connect(**db_config)\n",
    "\n",
    "def create_database(cursor, db_name):\n",
    "    \"\"\"Create a database if it doesn't exist.\"\"\"\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name};\")\n",
    "    print(f\"Database '{db_name}' checked/created.\")\n",
    "\n",
    "def connect_to_financial_database():\n",
    "    \"\"\"Connect to the financial database.\"\"\"\n",
    "    return mysql.connector.connect(**DB_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63328497-fd3a-4149-9e9e-428bd710966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(cursor, table_name):\n",
    "    \"\"\"Create a table for the ticker if it doesn't exist.\"\"\"\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        Date DATE PRIMARY KEY,\n",
    "        Open DECIMAL(15, 4),\n",
    "        High DECIMAL(15, 4),\n",
    "        Low DECIMAL(15, 4),\n",
    "        Close DECIMAL(15, 4),\n",
    "        Adj_Close DECIMAL(15, 4),\n",
    "        Volume BIGINT\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e40cafff-0979-4ecf-9479-bfedb9a3ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_views(cursor):\n",
    "    # 1. Daily Average Price View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        view_name = f\"{table_name}_daily_avg_price\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW {view_name} AS\n",
    "        SELECT\n",
    "            Date,\n",
    "            (Open + Close) / 2 AS Avg_Price\n",
    "        FROM {table_name};\n",
    "        \"\"\")\n",
    "        print(f\"View '{view_name}' created for daily average price.\")\n",
    "\n",
    "    # 2. Monthly Summary View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        view_name = f\"{table_name}_monthly_summary\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW {view_name} AS\n",
    "        SELECT\n",
    "            DATE_FORMAT(Date, '%Y-%m') AS Month,\n",
    "            AVG(Close) AS Avg_Close,\n",
    "            MAX(High) AS Max_High,\n",
    "            MIN(Low) AS Min_Low,\n",
    "            SUM(Volume) AS Total_Volume\n",
    "        FROM {table_name}\n",
    "        GROUP BY DATE_FORMAT(Date, '%Y-%m');\n",
    "        \"\"\")\n",
    "        print(f\"View '{view_name}' created for monthly summary.\")\n",
    "\n",
    "    # 3. Volatility View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        view_name = f\"{table_name}_volatility\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW {view_name} AS\n",
    "        SELECT\n",
    "            Date,\n",
    "            (Close - Open) / Open * 100 AS Daily_Percent_Change\n",
    "        FROM {table_name};\n",
    "        \"\"\")\n",
    "        print(f\"View '{view_name}' created for daily volatility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0661dd0-469b-4bc3-a053-09ab48b42ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_materialized_views(cursor):\n",
    "    # 1. Yearly Summary Materialized View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        yearly_summary_mv = f\"{table_name}_yearly_summary_mv\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {yearly_summary_mv} AS\n",
    "        SELECT\n",
    "            YEAR(Date) AS Year,\n",
    "            AVG(Open) AS Avg_Open,\n",
    "            AVG(Close) AS Avg_Close,\n",
    "            AVG(High) AS Avg_High,\n",
    "            AVG(Low) AS Avg_Low\n",
    "        FROM {table_name}\n",
    "        GROUP BY YEAR(Date)\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{yearly_summary_mv}' created for yearly summaries.\")\n",
    "\n",
    "    # 2. Moving Averages Materialized View (7-day and 30-day moving averages)\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        moving_avg_mv = f\"{table_name}_moving_averages_mv\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {moving_avg_mv} AS\n",
    "        SELECT\n",
    "            Date,\n",
    "            Close,\n",
    "            AVG(Close) OVER (ORDER BY Date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS Moving_Avg_7d,\n",
    "            AVG(Close) OVER (ORDER BY Date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS Moving_Avg_30d\n",
    "        FROM {table_name}\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{moving_avg_mv}' created for moving averages.\")\n",
    "\n",
    "    # 3. Volume Trend Materialized View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        volume_trend_mv = f\"{table_name}_volume_trend_mv\"\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {volume_trend_mv} AS\n",
    "        SELECT\n",
    "            Date,\n",
    "            Volume,\n",
    "            SUM(Volume) OVER (ORDER BY Date) AS Cumulative_Volume\n",
    "        FROM {table_name}\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{volume_trend_mv}' created for volume trends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e365b02-ce3e-44a1-9d03-bf83d946d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_materialized_views(cursor):\n",
    "    # Function to refresh each materialized view by truncating and re-inserting data\n",
    "    \n",
    "    # Yearly Summary Materialized View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        yearly_summary_mv = f\"{table_name}_yearly_summary_mv\"\n",
    "        \n",
    "        cursor.execute(f\"TRUNCATE TABLE {yearly_summary_mv};\")\n",
    "        cursor.execute(f\"\"\"\n",
    "        INSERT INTO {yearly_summary_mv}\n",
    "        SELECT\n",
    "            YEAR(Date) AS Year,\n",
    "            AVG(Open) AS Avg_Open,\n",
    "            AVG(Close) AS Avg_Close,\n",
    "            AVG(High) AS Avg_High,\n",
    "            AVG(Low) AS Avg_Low\n",
    "        FROM {table_name}\n",
    "        GROUP BY YEAR(Date)\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{yearly_summary_mv}' refreshed for yearly summaries.\")\n",
    "\n",
    "    # Moving Averages Materialized View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        moving_avg_mv = f\"{table_name}_moving_averages_mv\"\n",
    "        \n",
    "        cursor.execute(f\"TRUNCATE TABLE {moving_avg_mv};\")\n",
    "        cursor.execute(f\"\"\"\n",
    "        INSERT INTO {moving_avg_mv}\n",
    "        SELECT\n",
    "            Date,\n",
    "            Close,\n",
    "            AVG(Close) OVER (ORDER BY Date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS Moving_Avg_7d,\n",
    "            AVG(Close) OVER (ORDER BY Date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS Moving_Avg_30d\n",
    "        FROM {table_name}\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{moving_avg_mv}' refreshed for moving averages.\")\n",
    "\n",
    "    # Volume Trend Materialized View\n",
    "    for name in tickers:\n",
    "        table_name = name.replace(' ', '_')\n",
    "        volume_trend_mv = f\"{table_name}_volume_trend_mv\"\n",
    "        \n",
    "        cursor.execute(f\"TRUNCATE TABLE {volume_trend_mv};\")\n",
    "        cursor.execute(f\"\"\"\n",
    "        INSERT INTO {volume_trend_mv}\n",
    "        SELECT\n",
    "            Date,\n",
    "            Volume,\n",
    "            SUM(Volume) OVER (ORDER BY Date) AS Cumulative_Volume\n",
    "        FROM {table_name}\n",
    "        \"\"\")\n",
    "        print(f\"Materialized view '{volume_trend_mv}' refreshed for volume trends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c148d821-e79c-4d2e-acb3-e6449800117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_insert_data():\n",
    "    # Prompt user for database details\n",
    "    db_config = get_db_config()\n",
    "\n",
    "    # Connect to MySQL server (without database)\n",
    "    connection = connect_to_database({\n",
    "        'user': db_config['user'],\n",
    "        'password': db_config['password'],\n",
    "        'host': db_config['host']\n",
    "    })\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        # Check if the database exists and create it if it doesn't\n",
    "        create_database(cursor, db_config['database'])\n",
    "        connection.database = db_config['database']  \n",
    "\n",
    "        for name, ticker in tickers.items():\n",
    "            print(f\"Checking for new data for {name} ({ticker})...\")\n",
    "            \n",
    "            # Create the table for the ticker\n",
    "            create_table(cursor, name.replace(' ', '_'))\n",
    "\n",
    "            # Fetch existing data to find the last date\n",
    "            cursor.execute(f\"SELECT MAX(Date) FROM {name.replace(' ', '_')}\")\n",
    "            last_date = cursor.fetchone()[0]\n",
    "            \n",
    "            # Fetch new data from Yahoo Finance\n",
    "            if last_date is not None:\n",
    "                last_date = last_date.strftime('%Y-%m-%d')\n",
    "                start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "            else:\n",
    "                start_date = '2007-07-30'  # Default start date if no data exists\n",
    "\n",
    "            print(f\"Fetching data starting from {start_date}...\")\n",
    "            data = yf.download(ticker, start=start_date, end=datetime.now().strftime('%Y-%m-%d'), interval='1d')\n",
    "\n",
    "            # Check if data is empty\n",
    "            if not data.empty:\n",
    "                # Preprocess data to handle missing values\n",
    "                data.ffill(inplace=True)  # Forward fill for the entire DataFrame\n",
    "                if name == 'PLD':\n",
    "                    data['Close'].bfill(inplace=True)  # Backward fill for Palladium Futures Close column\n",
    "\n",
    "                # Check for remaining missing values\n",
    "                missing_values = data.isnull().sum()\n",
    "                print(f\"Missing values after filling for {name}:\\n{missing_values}\")\n",
    "\n",
    "                # If there are still missing values, print a warning\n",
    "                if missing_values.any():\n",
    "                    print(f\"Warning: Missing values still present in {name} after filling.\")\n",
    "\n",
    "                # Insert new data into the database\n",
    "                for date, row in data.iterrows():\n",
    "                    values = (\n",
    "                        date.strftime('%Y-%m-%d'),\n",
    "                        float(row['Open'].iloc[0]),\n",
    "                        float(row['High'].iloc[0]),\n",
    "                        float(row['Low'].iloc[0]),\n",
    "                        float(row['Close'].iloc[0]),\n",
    "                        float(row['Adj Close'].iloc[0]),\n",
    "                        int(row['Volume'].iloc[0])\n",
    "                    )\n",
    "\n",
    "                    # SQL insert statement with duplicate key handling\n",
    "                    sql = f\"\"\"\n",
    "                    INSERT INTO {name.replace(\" \", \"_\")} (Date, Open, High, Low, Close, Adj_Close, Volume)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON DUPLICATE KEY UPDATE\n",
    "                        Open=VALUES(Open), High=VALUES(High), Low=VALUES(Low),\n",
    "                        Close=VALUES(Close), Adj_Close=VALUES(Adj_Close), Volume=VALUES(Volume);\n",
    "                    \"\"\"\n",
    "\n",
    "                    # Execute insertion\n",
    "                    cursor.execute(sql, values)\n",
    "\n",
    "                # Commit changes to the database\n",
    "                connection.commit()\n",
    "                print(\"Data inserted successfully.\")\n",
    "\n",
    "        # Create regular views after all data is inserted\n",
    "        create_views(cursor)\n",
    "        print(\"Regular views created successfully.\")\n",
    "\n",
    "        # Create materialized views after all data is inserted\n",
    "        create_materialized_views(cursor)\n",
    "        print(\"Materialized views created successfully.\")\n",
    "\n",
    "        # Refresh materialized views\n",
    "        refresh_materialized_views(cursor)\n",
    "        connection.commit()\n",
    "        print(\"Materialized views refreshed successfully.\")\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77d1932e-fd7d-4572-a418-d75da8a05e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_and_insert_data():\n",
    "#     # Prompt user for database details\n",
    "#     db_config = get_db_config()\n",
    "\n",
    "#     # Connect to MySQL server (without database)\n",
    "#     connection = connect_to_database({\n",
    "#         'user': db_config['user'],\n",
    "#         'password': db_config['password'],\n",
    "#         'host': db_config['host']\n",
    "#     })\n",
    "\n",
    "#     cursor = connection.cursor()\n",
    "\n",
    "#     try:\n",
    "#         # Check if the database exists and create it if it doesn't\n",
    "#         create_database(cursor, db_config['database'])\n",
    "#         connection.database = db_config['database']  \n",
    "\n",
    "#         for name, ticker in tickers.items():\n",
    "#             print(f\"Checking for new data for {name} ({ticker})...\")\n",
    "            \n",
    "#             # Create the table for the ticker\n",
    "#             create_table(cursor, name.replace(' ', '_'))\n",
    "\n",
    "#             # Fetch existing data to find the last date\n",
    "#             cursor.execute(f\"SELECT MAX(Date) FROM {name.replace(' ', '_')}\")\n",
    "#             last_date = cursor.fetchone()[0]\n",
    "            \n",
    "#             # Fetch new data from Yahoo Finance\n",
    "#             if last_date is not None:\n",
    "#                 last_date = last_date.strftime('%Y-%m-%d')\n",
    "#                 start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "#             else:\n",
    "#                 start_date = '2007-07-30'  # Default start date if no data exists\n",
    "\n",
    "#             print(f\"Fetching data starting from {start_date}...\")\n",
    "#             data = yf.download(ticker, start=start_date, end=datetime.now().strftime('%Y-%m-%d'), interval='1d')\n",
    "\n",
    "#             if not data.empty:\n",
    "#                 print(f\"Data downloaded for {name}:\\n{data}\")\n",
    "\n",
    "#                 # Insert new data into the database\n",
    "#                 for date, row in data.iterrows():\n",
    "#                     values = (\n",
    "#                         date.strftime('%Y-%m-%d'),\n",
    "#                         float(row['Open'].iloc[0]),\n",
    "#                         float(row['High'].iloc[0]),\n",
    "#                         float(row['Low'].iloc[0]),\n",
    "#                         float(row['Close'].iloc[0]),\n",
    "#                         float(row['Adj Close'].iloc[0]),\n",
    "#                         int(row['Volume'].iloc[0])\n",
    "#                     )\n",
    "\n",
    "#                     # SQL insert statement with duplicate key handling\n",
    "#                     sql = f\"\"\"\n",
    "#                     INSERT INTO {name.replace(\" \", \"_\")} (Date, Open, High, Low, Close, Adj_Close, Volume)\n",
    "#                     VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "#                     ON DUPLICATE KEY UPDATE\n",
    "#                         Open=VALUES(Open), High=VALUES(High), Low=VALUES(Low),\n",
    "#                         Close=VALUES(Close), Adj_Close=VALUES(Adj_Close), Volume=VALUES(Volume);\n",
    "#                     \"\"\"\n",
    "\n",
    "#                     # Execute insertion\n",
    "#                     cursor.execute(sql, values)\n",
    "\n",
    "#                 # Commit changes to the database\n",
    "#                 connection.commit()\n",
    "#                 print(\"Data inserted successfully.\")\n",
    "\n",
    "#         # Create regular views after all data is inserted\n",
    "#         create_views(cursor)\n",
    "#         print(\"Regular views created successfully.\")\n",
    "\n",
    "#         # Create materialized views after all data is inserted\n",
    "#         create_materialized_views(cursor)\n",
    "#         print(\"Materialized views created successfully.\")\n",
    "\n",
    "#         # Refresh materialized views\n",
    "#         refresh_materialized_views(cursor)\n",
    "#         connection.commit()\n",
    "#         print(\"Materialized views refreshed successfully.\")\n",
    "\n",
    "\n",
    "#     except mysql.connector.Error as err:\n",
    "#         print(f\"Error: {err}\")\n",
    "#     finally:\n",
    "#         cursor.close()\n",
    "#         connection.close()\n",
    "#         print(\"MySQL connection closed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d930023b-62ec-4406-a594-9fa0e04d348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_and_insert_data():\n",
    "#     # Prompt user for database details\n",
    "#     db_config = get_db_config()\n",
    "\n",
    "#     # Connect to MySQL server (without database)\n",
    "#     connection = connect_to_database({\n",
    "#         'user': db_config['user'],\n",
    "#         'password': db_config['password'],\n",
    "#         'host': db_config['host']\n",
    "#     })\n",
    "\n",
    "#     cursor = connection.cursor()\n",
    "\n",
    "#     try:\n",
    "#         # Check if the database exists and create it if it doesn't\n",
    "#         create_database(cursor, db_config['database'])\n",
    "#         connection.database = db_config['database']  \n",
    "\n",
    "#         for name, ticker in tickers.items():\n",
    "#             print(f\"Checking for new data for {name} ({ticker})...\")\n",
    "            \n",
    "#             # Create the table for the ticker\n",
    "#             create_table(cursor, name.replace(' ', '_'))\n",
    "\n",
    "#             # Fetch existing data to find the last date\n",
    "#             cursor.execute(f\"SELECT MAX(Date) FROM {name.replace(' ', '_')}\")\n",
    "#             last_date = cursor.fetchone()[0]\n",
    "            \n",
    "#             # Fetch new data from Yahoo Finance\n",
    "#             if last_date is not None:\n",
    "#                 last_date = last_date.strftime('%Y-%m-%d')\n",
    "#                 start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "#             else:\n",
    "#                 start_date = '2007-07-30'  # Default start date if no data exists\n",
    "\n",
    "#             print(f\"Fetching data starting from {start_date}...\")\n",
    "#             data = yf.download(ticker, start=start_date, end=datetime.now().strftime('%Y-%m-%d'), interval='1d')\n",
    "\n",
    "#             if not data.empty:\n",
    "#                 print(f\"Data downloaded for {name}:\\n{data}\")\n",
    "\n",
    "#                 # Insert new data into the database\n",
    "#                 for date, row in data.iterrows():\n",
    "#                     values = (\n",
    "#                         date.strftime('%Y-%m-%d'),\n",
    "#                         float(row['Open'].iloc[0]),\n",
    "#                         float(row['High'].iloc[0]),\n",
    "#                         float(row['Low'].iloc[0]),\n",
    "#                         float(row['Close'].iloc[0]),\n",
    "#                         float(row['Adj Close'].iloc[0]),\n",
    "#                         int(row['Volume'].iloc[0])\n",
    "#                     )\n",
    "\n",
    "#                     # SQL insert statement with duplicate key handling\n",
    "#                     sql = f\"\"\"\n",
    "#                     INSERT INTO {name.replace(\" \", \"_\")} (Date, Open, High, Low, Close, Adj_Close, Volume)\n",
    "#                     VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "#                     ON DUPLICATE KEY UPDATE\n",
    "#                         Open=VALUES(Open), High=VALUES(High), Low=VALUES(Low),\n",
    "#                         Close=VALUES(Close), Adj_Close=VALUES(Adj_Close), Volume=VALUES(Volume);\n",
    "#                     \"\"\"\n",
    "\n",
    "#                     # Execute insertion\n",
    "#                     cursor.execute(sql, values)\n",
    "\n",
    "#                 # Commit changes to the database\n",
    "#                 connection.commit()\n",
    "#                 print(\"Data inserted successfully.\")\n",
    "\n",
    "#     except mysql.connector.Error as err:\n",
    "#         print(f\"Error: {err}\")\n",
    "#     finally:\n",
    "#         cursor.close()\n",
    "#         connection.close()\n",
    "#         print(\"MySQL connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "480b57ee-2760-4504-92d7-4f1ad655afff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the database host (default: localhost):  localhost\n",
      "Enter your database username (default: root):  root\n",
      "Enter your database password:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'financial_data' checked/created.\n",
      "Checking for new data for GOLD_FUTURES (GC=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for GOLD_FUTURES:\n",
      "Price      Ticker\n",
      "Adj Close  GC=F      0\n",
      "Close      GC=F      0\n",
      "High       GC=F      0\n",
      "Low        GC=F      0\n",
      "Open       GC=F      0\n",
      "Volume     GC=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for SP_INDEX (^GSPC)...\n",
      "Fetching data starting from 2007-07-30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling for SP_INDEX:\n",
      "Price      Ticker\n",
      "Adj Close  ^GSPC     0\n",
      "Close      ^GSPC     0\n",
      "High       ^GSPC     0\n",
      "Low        ^GSPC     0\n",
      "Open       ^GSPC     0\n",
      "Volume     ^GSPC     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for DJ_INDEX (^DJI)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for DJ_INDEX:\n",
      "Price      Ticker\n",
      "Adj Close  ^DJI      0\n",
      "Close      ^DJI      0\n",
      "High       ^DJI      0\n",
      "Low        ^DJI      0\n",
      "Open       ^DJI      0\n",
      "Volume     ^DJI      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for EG_CORP (EGO)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for EG_CORP:\n",
      "Price      Ticker\n",
      "Adj Close  EGO       0\n",
      "Close      EGO       0\n",
      "High       EGO       0\n",
      "Low        EGO       0\n",
      "Open       EGO       0\n",
      "Volume     EGO       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for EUR_USD (EURUSD=X)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for EUR_USD:\n",
      "Price      Ticker  \n",
      "Adj Close  EURUSD=X    0\n",
      "Close      EURUSD=X    0\n",
      "High       EURUSD=X    0\n",
      "Low        EURUSD=X    0\n",
      "Open       EURUSD=X    0\n",
      "Volume     EURUSD=X    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for OIL_FUTURES (BZ=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for OIL_FUTURES:\n",
      "Price      Ticker\n",
      "Adj Close  BZ=F      0\n",
      "Close      BZ=F      0\n",
      "High       BZ=F      0\n",
      "Low        BZ=F      0\n",
      "Open       BZ=F      0\n",
      "Volume     BZ=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for WTI_OIL (CL=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for WTI_OIL:\n",
      "Price      Ticker\n",
      "Adj Close  CL=F      0\n",
      "Close      CL=F      0\n",
      "High       CL=F      0\n",
      "Low        CL=F      0\n",
      "Open       CL=F      0\n",
      "Volume     CL=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for SILVER_FUTURES (SI=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for SILVER_FUTURES:\n",
      "Price      Ticker\n",
      "Adj Close  SI=F      0\n",
      "Close      SI=F      0\n",
      "High       SI=F      0\n",
      "Low        SI=F      0\n",
      "Open       SI=F      0\n",
      "Volume     SI=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for US_BOND_RATE (^TNX)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for US_BOND_RATE:\n",
      "Price      Ticker\n",
      "Adj Close  ^TNX      0\n",
      "Close      ^TNX      0\n",
      "High       ^TNX      0\n",
      "Low        ^TNX      0\n",
      "Open       ^TNX      0\n",
      "Volume     ^TNX      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for PLATINUM_FUTURES (PL=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for PLATINUM_FUTURES:\n",
      "Price      Ticker\n",
      "Adj Close  PL=F      0\n",
      "Close      PL=F      0\n",
      "High       PL=F      0\n",
      "Low        PL=F      0\n",
      "Open       PL=F      0\n",
      "Volume     PL=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for PALLADIUM_FUTURES (PA=F)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for PALLADIUM_FUTURES:\n",
      "Price      Ticker\n",
      "Adj Close  PA=F      0\n",
      "Close      PA=F      0\n",
      "High       PA=F      0\n",
      "Low        PA=F      0\n",
      "Open       PA=F      0\n",
      "Volume     PA=F      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for GOLD_MINERS (GDX)...\n",
      "Fetching data starting from 2007-07-30...\n",
      "Missing values after filling for GOLD_MINERS:\n",
      "Price      Ticker\n",
      "Adj Close  GDX       0\n",
      "Close      GDX       0\n",
      "High       GDX       0\n",
      "Low        GDX       0\n",
      "Open       GDX       0\n",
      "Volume     GDX       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for OIL_ETF (USO)...\n",
      "Fetching data starting from 2007-07-30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling for OIL_ETF:\n",
      "Price      Ticker\n",
      "Adj Close  USO       0\n",
      "Close      USO       0\n",
      "High       USO       0\n",
      "Low        USO       0\n",
      "Open       USO       0\n",
      "Volume     USO       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully.\n",
      "Checking for new data for USD_INDEX (DX-Y.NYB)...\n",
      "Fetching data starting from 2007-07-30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling for USD_INDEX:\n",
      "Price      Ticker  \n",
      "Adj Close  DX-Y.NYB    0\n",
      "Close      DX-Y.NYB    0\n",
      "High       DX-Y.NYB    0\n",
      "Low        DX-Y.NYB    0\n",
      "Open       DX-Y.NYB    0\n",
      "Volume     DX-Y.NYB    0\n",
      "dtype: int64\n",
      "Data inserted successfully.\n",
      "View 'GOLD_FUTURES_daily_avg_price' created for daily average price.\n",
      "View 'SP_INDEX_daily_avg_price' created for daily average price.\n",
      "View 'DJ_INDEX_daily_avg_price' created for daily average price.\n",
      "View 'EG_CORP_daily_avg_price' created for daily average price.\n",
      "View 'EUR_USD_daily_avg_price' created for daily average price.\n",
      "View 'OIL_FUTURES_daily_avg_price' created for daily average price.\n",
      "View 'WTI_OIL_daily_avg_price' created for daily average price.\n",
      "View 'SILVER_FUTURES_daily_avg_price' created for daily average price.\n",
      "View 'US_BOND_RATE_daily_avg_price' created for daily average price.\n",
      "View 'PLATINUM_FUTURES_daily_avg_price' created for daily average price.\n",
      "View 'PALLADIUM_FUTURES_daily_avg_price' created for daily average price.\n",
      "View 'GOLD_MINERS_daily_avg_price' created for daily average price.\n",
      "View 'OIL_ETF_daily_avg_price' created for daily average price.\n",
      "View 'USD_INDEX_daily_avg_price' created for daily average price.\n",
      "View 'GOLD_FUTURES_monthly_summary' created for monthly summary.\n",
      "View 'SP_INDEX_monthly_summary' created for monthly summary.\n",
      "View 'DJ_INDEX_monthly_summary' created for monthly summary.\n",
      "View 'EG_CORP_monthly_summary' created for monthly summary.\n",
      "View 'EUR_USD_monthly_summary' created for monthly summary.\n",
      "View 'OIL_FUTURES_monthly_summary' created for monthly summary.\n",
      "View 'WTI_OIL_monthly_summary' created for monthly summary.\n",
      "View 'SILVER_FUTURES_monthly_summary' created for monthly summary.\n",
      "View 'US_BOND_RATE_monthly_summary' created for monthly summary.\n",
      "View 'PLATINUM_FUTURES_monthly_summary' created for monthly summary.\n",
      "View 'PALLADIUM_FUTURES_monthly_summary' created for monthly summary.\n",
      "View 'GOLD_MINERS_monthly_summary' created for monthly summary.\n",
      "View 'OIL_ETF_monthly_summary' created for monthly summary.\n",
      "View 'USD_INDEX_monthly_summary' created for monthly summary.\n",
      "View 'GOLD_FUTURES_volatility' created for daily volatility.\n",
      "View 'SP_INDEX_volatility' created for daily volatility.\n",
      "View 'DJ_INDEX_volatility' created for daily volatility.\n",
      "View 'EG_CORP_volatility' created for daily volatility.\n",
      "View 'EUR_USD_volatility' created for daily volatility.\n",
      "View 'OIL_FUTURES_volatility' created for daily volatility.\n",
      "View 'WTI_OIL_volatility' created for daily volatility.\n",
      "View 'SILVER_FUTURES_volatility' created for daily volatility.\n",
      "View 'US_BOND_RATE_volatility' created for daily volatility.\n",
      "View 'PLATINUM_FUTURES_volatility' created for daily volatility.\n",
      "View 'PALLADIUM_FUTURES_volatility' created for daily volatility.\n",
      "View 'GOLD_MINERS_volatility' created for daily volatility.\n",
      "View 'OIL_ETF_volatility' created for daily volatility.\n",
      "View 'USD_INDEX_volatility' created for daily volatility.\n",
      "Regular views created successfully.\n",
      "Materialized view 'GOLD_FUTURES_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'SP_INDEX_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'DJ_INDEX_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'EG_CORP_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'EUR_USD_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'OIL_FUTURES_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'WTI_OIL_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'SILVER_FUTURES_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'US_BOND_RATE_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'PLATINUM_FUTURES_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'PALLADIUM_FUTURES_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'GOLD_MINERS_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'OIL_ETF_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'USD_INDEX_yearly_summary_mv' created for yearly summaries.\n",
      "Materialized view 'GOLD_FUTURES_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'SP_INDEX_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'DJ_INDEX_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'EG_CORP_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'EUR_USD_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'OIL_FUTURES_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'WTI_OIL_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'SILVER_FUTURES_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'US_BOND_RATE_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'PLATINUM_FUTURES_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'PALLADIUM_FUTURES_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'GOLD_MINERS_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'OIL_ETF_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'USD_INDEX_moving_averages_mv' created for moving averages.\n",
      "Materialized view 'GOLD_FUTURES_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'SP_INDEX_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'DJ_INDEX_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'EG_CORP_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'EUR_USD_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'OIL_FUTURES_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'WTI_OIL_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'SILVER_FUTURES_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'US_BOND_RATE_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'PLATINUM_FUTURES_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'PALLADIUM_FUTURES_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'GOLD_MINERS_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'OIL_ETF_volume_trend_mv' created for volume trends.\n",
      "Materialized view 'USD_INDEX_volume_trend_mv' created for volume trends.\n",
      "Materialized views created successfully.\n",
      "Materialized view 'GOLD_FUTURES_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'SP_INDEX_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'DJ_INDEX_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'EG_CORP_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'EUR_USD_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'OIL_FUTURES_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'WTI_OIL_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'SILVER_FUTURES_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'US_BOND_RATE_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'PLATINUM_FUTURES_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'PALLADIUM_FUTURES_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'GOLD_MINERS_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'OIL_ETF_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'USD_INDEX_yearly_summary_mv' refreshed for yearly summaries.\n",
      "Materialized view 'GOLD_FUTURES_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'SP_INDEX_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'DJ_INDEX_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'EG_CORP_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'EUR_USD_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'OIL_FUTURES_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'WTI_OIL_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'SILVER_FUTURES_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'US_BOND_RATE_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'PLATINUM_FUTURES_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'PALLADIUM_FUTURES_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'GOLD_MINERS_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'OIL_ETF_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'USD_INDEX_moving_averages_mv' refreshed for moving averages.\n",
      "Materialized view 'GOLD_FUTURES_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'SP_INDEX_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'DJ_INDEX_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'EG_CORP_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'EUR_USD_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'OIL_FUTURES_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'WTI_OIL_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'SILVER_FUTURES_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'US_BOND_RATE_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'PLATINUM_FUTURES_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'PALLADIUM_FUTURES_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'GOLD_MINERS_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'OIL_ETF_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized view 'USD_INDEX_volume_trend_mv' refreshed for volume trends.\n",
      "Materialized views refreshed successfully.\n",
      "MySQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "fetch_and_insert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc548b-9d6d-4d12-ae84-a015bbb729d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
